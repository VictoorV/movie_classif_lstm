{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVrTGJWxRsMYxcxMb3xCPR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictoorV/movie_classif_lstm/blob/main/Film_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchtext==0.15.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BlrgZFCLyD18",
        "outputId": "9464789f-db71-4f9e-fcf8-61ab4c68fb07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Collecting torch==2.0.1 (from torchtext==0.15.2)\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (3.31.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n",
            "Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbS-jOpcGjuT",
        "outputId": "d0523cc5-6907-4db9-ab80-fd7525f97a90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hy5sOtPEpwJC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "Kxf41O9wGNHt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "\n",
        "for label, text in train_iter:\n",
        "    print(f\"Label: {label}, Texte: {text[:200]}...\\n\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5vZnp-L7MqS",
        "outputId": "50a1a8f3-80da-4a79-eaeb-7b46604c9ba3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1, Texte: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ev...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "\n",
        "vocabulary = build_vocab_from_iterator(\n",
        "    yield_tokens(IMDB(split='train')),\n",
        "    specials=[\"<pad>\", \"<unk>\"])\n",
        "vocabulary.set_default_index(vocabulary[\"<unk>\"])"
      ],
      "metadata": {
        "id": "SGGhW7gnEi4M"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocabulary))\n",
        "print(vocabulary['<pad>'])\n",
        "print(vocabulary[\".\"])\n",
        "print(vocabulary.get_itos()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrVouREqJO94",
        "outputId": "b22e95ed-1398-4249-bcad-d36e62f46b2e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100684\n",
            "0\n",
            "3\n",
            "<pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)"
      ],
      "metadata": {
        "id": "gVa1Mm2R37r6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\n",
        "    (2, \"This movie was really great !\"),\n",
        "    (1, \"I am not sure about the scenario.\"),\n",
        "    (1, \"It was not as good as I expected\"),\n",
        "    (2, \"The actors were good.\")\n",
        "]"
      ],
      "metadata": {
        "id": "qQ74xRnrSEON"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "  labels, samples = zip(*batch)\n",
        "  labels = torch.tensor(labels, dtype=torch.int64) - 1\n",
        "  processed_text = [torch.tensor(vocabulary(tokenizer(sample)), dtype=torch.int64) for sample in samples]\n",
        "  processed_text = pad_sequence(processed_text, batch_first=True, padding_value=0)\n",
        "  return labels, processed_text"
      ],
      "metadata": {
        "id": "Pu2d0_KN2wRW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_batch(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9DfFjHpLfhe",
        "outputId": "d28d1ebd-5de9-4329-c6ba-b7231e8969e6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 0, 0, 1]),\n",
              " tensor([[  14,   21,   17,   72,   93,   36,    0,    0],\n",
              "         [  13,  246,   29,  254,   50,    2, 2652,    3],\n",
              "         [  11,   17,   29,   18,   57,   18,   13,  853],\n",
              "         [   2,  162,   77,   57,    3,    0,    0,    0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "TD2FOx88MXZu"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 embedding_size,\n",
        "                 hidden_size,\n",
        "                 num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding field\n",
        "        self.embedding = torch.nn.EmbeddingBag(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_size)\n",
        "\n",
        "        # LSTM cell\n",
        "        self.rnn = torch.nn.LSTM(\n",
        "            input_size=embedding_size,\n",
        "            hidden_size=hidden_size)\n",
        "\n",
        "        # Fully connected output\n",
        "        self.fc = torch.nn.Linear(\n",
        "            hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, text_sequence, offsets):\n",
        "        # Extract embedding vectors\n",
        "        embeddings = self.embedding(\n",
        "            text_sequence, offsets)\n",
        "\n",
        "        h_t, c_t = self.rnn(embeddings)\n",
        "\n",
        "        return self.fc(h_t)"
      ],
      "metadata": {
        "id": "Kk2K8xLbj3S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(\n",
        "    vocab_size=len(vocabulary),\n",
        "    embedding_size=64,\n",
        "    hidden_size=64,\n",
        "    num_classes=2)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB8q2HZTkGwT",
        "outputId": "baa37291-ce7b-4f64-abf7-c6f41a2f6d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): EmbeddingBag(68811, 64, mode='mean')\n",
              "  (rnn): LSTM(64, 64)\n",
              "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(samples, offsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UemVScsAnta6",
        "outputId": "ae837e67-9038-44e4-fa83-644fe20aae77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0258, -0.1070],\n",
              "        [-0.0338, -0.1114],\n",
              "        [-0.0308, -0.1197]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = torch.nn.EmbeddingBag(\n",
        "            num_embeddings=len(vocabulary),\n",
        "            embedding_dim=64)"
      ],
      "metadata": {
        "id": "GcX63skoosE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = [\"i\"]\n",
        "sentence2 = [\"o\"]\n",
        "emb1 = (embedding(torch.tensor([vocabulary[word] for word in sentence1]), torch.tensor([0])) + embedding(torch.tensor([vocabulary[word] for word in sentence2]), torch.tensor([0]))) / 2\n",
        "emb1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5qKZOexo09N",
        "outputId": "4c17eb60-9631-485e-e6b7-9fbf42d99735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.8664, -0.4567,  0.3141, -0.1556,  0.0163,  1.3712, -0.1701,  0.2778,\n",
              "         -0.4237,  0.2656, -0.5882, -1.1098, -0.0335, -0.2935, -0.3800, -0.3045,\n",
              "          0.0258,  0.1059,  0.6513, -0.5410, -0.0226,  0.2351, -0.2023,  0.2163,\n",
              "          0.4305, -0.2674, -0.0916, -0.6420,  1.0534, -0.3949,  0.2352,  0.0269,\n",
              "         -0.5869, -0.3753,  0.2741,  0.2824,  0.3127, -0.3130,  0.4537,  0.2205,\n",
              "         -1.0100, -0.3071, -0.6559, -0.3089, -0.1188, -0.1077,  0.8178, -0.5964,\n",
              "         -0.9895, -0.9986,  0.6122,  1.3127, -0.3148, -0.5196,  0.0114,  0.1211,\n",
              "          0.3754,  0.2024, -0.2701, -0.0778,  0.4079,  0.2358, -0.5978,  0.4146]],\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [\"i\", \"o\"]\n",
        "emb2 = embedding(torch.tensor([vocabulary[word] for word in sentence]), torch.tensor([0]))\n",
        "emb2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbBP4nD1p_Yj",
        "outputId": "aefee1b1-998b-490d-9e35-2d1c2f26b768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.8664, -0.4567,  0.3141, -0.1556,  0.0163,  1.3712, -0.1701,  0.2778,\n",
              "         -0.4237,  0.2656, -0.5882, -1.1098, -0.0335, -0.2935, -0.3800, -0.3045,\n",
              "          0.0258,  0.1059,  0.6513, -0.5410, -0.0226,  0.2351, -0.2023,  0.2163,\n",
              "          0.4305, -0.2674, -0.0916, -0.6420,  1.0534, -0.3949,  0.2352,  0.0269,\n",
              "         -0.5869, -0.3753,  0.2741,  0.2824,  0.3127, -0.3130,  0.4537,  0.2205,\n",
              "         -1.0100, -0.3071, -0.6559, -0.3089, -0.1188, -0.1077,  0.8178, -0.5964,\n",
              "         -0.9895, -0.9986,  0.6122,  1.3127, -0.3148, -0.5196,  0.0114,  0.1211,\n",
              "          0.3754,  0.2024, -0.2701, -0.0778,  0.4079,  0.2358, -0.5978,  0.4146]],\n",
              "       grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb3 = embedding(samples, offsets)\n",
        "emb3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXOANk5lbVaY",
        "outputId": "582008ab-3751-453b-c168-8ebdc5d0434f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.LSTM(\n",
        "            input_size=64,\n",
        "            hidden_size=64)"
      ],
      "metadata": {
        "id": "irG-tqvMf8Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(emb3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3L8C_vfgAv0",
        "outputId": "13f36a34-cd75-4938-fb20-195d0c4cb295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.0115,  0.0661, -0.0380,  0.0048,  0.0971, -0.0240,  0.0258, -0.0097,\n",
              "           0.0539,  0.1063,  0.0462,  0.0199,  0.0019,  0.0048, -0.0120,  0.0817,\n",
              "           0.0036, -0.0164, -0.0205, -0.1330,  0.0435,  0.0163, -0.0500, -0.0859,\n",
              "          -0.0403, -0.0006,  0.0363,  0.0721,  0.0613,  0.0279,  0.0826,  0.0775,\n",
              "           0.0979,  0.0611, -0.0626,  0.0768,  0.0114,  0.0166,  0.0557, -0.0022,\n",
              "          -0.0427,  0.0508, -0.0753, -0.0155, -0.0181,  0.0291,  0.0247,  0.0293,\n",
              "          -0.0934,  0.0317,  0.1167,  0.0143,  0.0903,  0.0906, -0.1311,  0.0290,\n",
              "           0.0263, -0.0328, -0.0298, -0.0304, -0.0500, -0.0012, -0.0649,  0.0244],\n",
              "         [ 0.0168,  0.1037, -0.0860,  0.0758,  0.1072, -0.0474, -0.0260, -0.0338,\n",
              "          -0.0400,  0.0824,  0.0333,  0.0111,  0.0433, -0.0592, -0.0192,  0.0420,\n",
              "           0.0507, -0.0307,  0.0935, -0.0480,  0.0145,  0.0184, -0.0645, -0.0929,\n",
              "           0.0341, -0.0146,  0.0212,  0.1205,  0.1311,  0.0501,  0.0434,  0.1144,\n",
              "           0.1454,  0.0165, -0.0339,  0.0586, -0.0288,  0.0319,  0.0475,  0.0044,\n",
              "          -0.0628,  0.0665, -0.1004,  0.0225, -0.0557, -0.0074,  0.0373,  0.0365,\n",
              "          -0.1398,  0.0860,  0.0513, -0.0586,  0.0429,  0.0115, -0.0560, -0.0395,\n",
              "          -0.0769,  0.0975, -0.0297, -0.0204, -0.0122,  0.0443, -0.0075,  0.0416],\n",
              "         [-0.0343, -0.0296, -0.0771,  0.0780,  0.2256,  0.0376, -0.0125,  0.0455,\n",
              "          -0.0184,  0.1824,  0.0569, -0.0110,  0.1502, -0.0152, -0.0303,  0.0066,\n",
              "           0.0804, -0.1627,  0.1400, -0.0631, -0.0151,  0.0362, -0.0829, -0.1270,\n",
              "           0.1050,  0.0554, -0.0462,  0.1475,  0.0790,  0.0894, -0.0314,  0.0892,\n",
              "           0.1924, -0.0035,  0.0447,  0.0548, -0.0440,  0.0028,  0.1110,  0.0025,\n",
              "          -0.0666,  0.0270, -0.0617, -0.0251, -0.0620, -0.0474,  0.0746,  0.0312,\n",
              "          -0.0318,  0.1031, -0.0112, -0.1047, -0.0463, -0.1018, -0.0326, -0.0824,\n",
              "          -0.0704,  0.1598,  0.0019, -0.0072, -0.0327, -0.0430,  0.0073,  0.0398]],\n",
              "        grad_fn=<SqueezeBackward1>),\n",
              " (tensor([[-0.0343, -0.0296, -0.0771,  0.0780,  0.2256,  0.0376, -0.0125,  0.0455,\n",
              "           -0.0184,  0.1824,  0.0569, -0.0110,  0.1502, -0.0152, -0.0303,  0.0066,\n",
              "            0.0804, -0.1627,  0.1400, -0.0631, -0.0151,  0.0362, -0.0829, -0.1270,\n",
              "            0.1050,  0.0554, -0.0462,  0.1475,  0.0790,  0.0894, -0.0314,  0.0892,\n",
              "            0.1924, -0.0035,  0.0447,  0.0548, -0.0440,  0.0028,  0.1110,  0.0025,\n",
              "           -0.0666,  0.0270, -0.0617, -0.0251, -0.0620, -0.0474,  0.0746,  0.0312,\n",
              "           -0.0318,  0.1031, -0.0112, -0.1047, -0.0463, -0.1018, -0.0326, -0.0824,\n",
              "           -0.0704,  0.1598,  0.0019, -0.0072, -0.0327, -0.0430,  0.0073,  0.0398]],\n",
              "         grad_fn=<SqueezeBackward1>),\n",
              "  tensor([[-0.0592, -0.0679, -0.1722,  0.1458,  0.4727,  0.0577, -0.0222,  0.1104,\n",
              "           -0.0337,  0.3516,  0.1064, -0.0272,  0.2359, -0.0327, -0.0826,  0.0149,\n",
              "            0.2194, -0.2984,  0.3311, -0.1344, -0.0362,  0.1036, -0.1526, -0.2734,\n",
              "            0.1933,  0.1094, -0.1073,  0.3254,  0.1411,  0.1736, -0.0557,  0.1934,\n",
              "            0.4119, -0.0062,  0.0806,  0.1210, -0.0876,  0.0055,  0.2370,  0.0058,\n",
              "           -0.1090,  0.0457, -0.1299, -0.0669, -0.1156, -0.0940,  0.1261,  0.0586,\n",
              "           -0.0538,  0.1854, -0.0262, -0.2829, -0.0994, -0.2141, -0.0761, -0.1653,\n",
              "           -0.1655,  0.2506,  0.0040, -0.0147, -0.0658, -0.0920,  0.0142,  0.0635]],\n",
              "         grad_fn=<SqueezeBackward1>)))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}